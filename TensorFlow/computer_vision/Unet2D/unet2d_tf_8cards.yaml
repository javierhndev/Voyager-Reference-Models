apiVersion: kubeflow.org/v2beta1
kind: MPIJob
metadata:
  name: yourusername-unet2d-8cards
  namespace: yourusername-restricted
spec:
  slotsPerWorker: 8
  runPolicy:
    cleanPodPolicy: Running
  mpiReplicaSpecs:
    Launcher:
      replicas: 1
      template:
        spec:
          nodeSelector:
            brightcomputing.com/node-category: 'compute'
          serviceAccountName: yourusername
          volumes:
            - name: mydir
              hostPath:
                path: /home/yourusername/models/voyager/unet2d_tf/1.15.1
                type: Directory
            - name: scratch
              emptyDir: {}
            - name: dataset
              hostPath:
                path: /voyager/ceph/users/yourusername/datasets/UNet2D_tf
                type: Directory
            - name: output
              hostPath:
                path: /voyager/ceph/users/yourusername/results/unet2d_tf/8cards
                type: Directory
          containers:
            - image: vault.habana.ai/gaudi-docker/1.13.0/ubuntu22.04/habanalabs/tensorflow-installer-tf-cpu-2.13.1
              name: unet2d-launcher
              resources:
                requests:
                  cpu: 2
                  memory: 4Gi
                limits:
                  cpu: 4
                  memory: 8Gi
              volumeMounts:
                - name: mydir
                  mountPath: /mydir
                - name: scratch
                  mountPath: /scratch
                - name: dataset
                  mountPath: /dataset
                - name: output
                  mountPath: /output
              command: ["/bin/bash", "-c"]
              args:
                - >-
                  declare -xr NUM_NODES=1;
                  declare -xr NGPU_PER_NODE=8;
                  declare -xr N_CARDS=$((NUM_NODES*NGPU_PER_NODE));

                  declare -xr RUN_PATH=/mydir;
                  declare -xr SYNAPSE_AI_VER=1.13.0;
                  declare -xr MODEL_PATH=/scratch/Model-References/TensorFlow/computer_vision/Unet2D;

                  declare -xr PYTHONPATH=$PYTHONPATH:/scratch/Model-References;

                  sleep 20s;

                  mpirun  --npernode 1 \
                    --tag-output \
                    --allow-run-as-root \
                    --prefix $MPI_ROOT \
                    -x MODEL_PATH \
                    -x SYNAPSE_AI_VER \
                    $RUN_PATH/setup.sh;

                  declare -xr CMD="python3 $MODEL_PATH/unet2d.py --data_dir /dataset \
                                   --batch_size 8 \
                                   --dtype bf16 \
                                   --model_dir /output \
                                   --fold 0 \
                                   --tensorboard_logging \
                                   --log_all_workers \
                                   --use_horovod";

                  mpirun -np ${N_CARDS} \
                    --allow-run-as-root \
                    --bind-to core \
                    --map-by ppr:4:socket:PE=6 \
                    -rank-by core --report-bindings \
                    --tag-output \
                    --merge-stderr-to-stdout --prefix $MPI_ROOT \
                    -x PYTHONPATH \
                    -x HOME \
                    $CMD;

    Worker:
      replicas: 1
      template:
        spec:
          serviceAccountName: yourusername
          volumes:
            - name: mydir
              hostPath:
                path: /home/yourusername/models/voyager/unet2d_tf/1.15.1
                type: Directory
            - name: scratch
              emptyDir: {}
            - name: dataset
              hostPath:
                path: /voyager/ceph/users/yourusername/datasets/UNet2D_tf
                type: Directory
            - name: output
              hostPath:
                path: /voyager/ceph/users/yourusername/results/unet2d_tf/8cards
                type: Directory
          containers:
            - image: vault.habana.ai/gaudi-docker/1.13.0/ubuntu22.04/habanalabs/tensorflow-installer-tf-cpu-2.13.1
              name: unet2d-worker
              imagePullPolicy: Always
              resources:
                limits:
                  habana.ai/gaudi: 8
                  cpu: 95
                  memory: 409Gi
                  hugepages-2Mi: 95000Mi
                requests:
                  habana.ai/gaudi: 8
                  cpu: 95
                  memory: 409Gi
                  hugepages-2Mi: 95000Mi
              volumeMounts:
                - name: mydir
                  mountPath: /mydir
                - name: scratch
                  mountPath: /scratch
                - name: dataset
                  mountPath: /dataset
                - name: output
                  mountPath: /output
 
