apiVersion: v1
kind: Pod
metadata:
  name: resnet-keras
spec:
  restartPolicy: Never
  volumes:
    - name: scratch
      emptyDir: {}
    - name: ceph
      hostPath:
        path: /voyager/ceph/users/yourusername
        type: Directory
  containers:
    - name: gaudi-container
      image: vault.habana.ai/gaudi-docker/1.11.0/ubuntu22.04/habanalabs/tensorflow-installer-tf-cpu-2.12.1:latest
      volumeMounts:
        - mountPath: /scratch
          name: scratch
        - mountPath: /ceph
          name: ceph 
      resources:
        limits:
          memory: 32G
          cpu: 6
          habana.ai/gaudi: 1
          hugepages-2Mi: 95000Mi
        requests:
          memory: 32G
          cpu: 6
          habana.ai/gaudi: 1
          hugepages-2Mi: 95000Mi
      env:
        - name: dataset
          value: "/ceph/datasets/imagenet/ILSVRC2012/tf_records"
        - name: output
          value: "/ceph/results/resnet_keras/1card"
      command: ["/bin/sh","-c"]
      args:
         - hl-smi;
           export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libjemalloc.so.2;
           export HOME=/scratch/tmp;
           cd /scratch;
           mkdir -p tmp;
           git clone -b 1.11.0 https://github.com/HabanaAI/Model-References;
           export PYTHONPATH=$PYTHONPATH:/scratch/Model-References/;
           cd /scratch/Model-References/TensorFlow/computer_vision/Resnets/resnet_keras;
           python3 -m pip install -r requirements.txt;
           python3 resnet_ctl_imagenet_main.py -bs 256 -te 40 -ebe 40 -dt bf16 --data_dir ${dataset} --model_dir ${output} --optimizer LARS --base_learning_rate 2.5 --warmup_epochs 3 --lr_schedule polynomial --label_smoothing 0.1 --weight_decay 0.0001  --single_l2_loss_op --enable_tensorboard;

