apiVersion: v1
kind: Pod
metadata:
  name: bloom
spec:
  restartPolicy: Never
  volumes:
    - name: scratch
      emptyDir: {}
    - name: dataset
      hostPath:
        path: /voyager/ceph/users/yourusername/datasets/bloom/checkpoints
        type: Directory
  containers:
    - name: gaudi-container
      image: vault.habana.ai/gaudi-docker/1.15.1/ubuntu22.04/habanalabs/pytorch-installer-2.2.0:latest
      volumeMounts:
        - mountPath: /scratch
          name: scratch
        - mountPath: /dataset
          name: dataset 
      resources:
        limits:
          memory: 32G
          cpu: 12
          habana.ai/gaudi: 1
          hugepages-2Mi: 95000Mi
        requests:
          memory: 32G
          cpu: 12
          habana.ai/gaudi: 1
          hugepages-2Mi: 95000Mi
          #env:
          #- name: dataset
          #value: "/ceph/datasets/bloom/checkpoints"
      command: ["/bin/sh","-c"]
      args:
        - hl-smi;
          export HOME=/scratch/tmp;
          export PYTHONPATH=/scratch/Model-References:$PYTHONPATH;
          export PATH=/scratch/tmp/.local/bin:$PATH;
          mkdir -p /scratch/tmp/;
          cd /scratch;
          git clone -b 1.15.1 https://github.com/HabanaAI/Model-References;
          cd Model-References/PyTorch/nlp/bloom;
          python3 -m pip install -r requirements.txt;
          python3 ./bloom.py --weights /dataset --model bloom-3b --options "max_length=32" "Do robots think?";

         

